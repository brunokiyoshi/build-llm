{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cf0a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corporate proxy configuration\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "try:\n",
    "    from _proxy_config import *\n",
    "except ImportError:\n",
    "    print(\"Warning: _proxy_config.py not found. Proxy settings may not be configured.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading proxy configuration: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac94d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mermaid as md\n",
    "from mermaid.graph import Graph\n",
    "import inspect\n",
    "from build_llm_module.SimpleTokenizer import SimpleTokenizer\n",
    "from build_llm_module.SelfAttention import SelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a61e3",
   "metadata": {},
   "source": [
    "# Attention mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086ba03",
   "metadata": {},
   "source": [
    "Before modern LLM's, language tasks were performed by other neural network architectures such as RNN's. Some of these tasks, such as translations, relied on two parts: an encoder and a decoder.\n",
    "\n",
    "The encoder would be fed a text input in the source language and result in a hidden state. That would then be fed into the decoder to be transformed back into the target natural language.\n",
    "\n",
    "However, text translations are not done by simply translating word after word. Different languages have different grammatical structures, where sentence entities can come in different orders and sometimes a word in a language could need multiple words in another language (and vice-versa).\n",
    "\n",
    "The RNN's were good enough for short sentences, but the decoder's lack of access to previous words in the input made them unsuitable for longer texts. The Bahdanau attention mechanism was proposed in 2014 to fix that, giving the RNN's decoder the ability to selectively access different parts of the input sequence at each decoding step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bd3d2",
   "metadata": {},
   "source": [
    "## 1. Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbba1d5",
   "metadata": {},
   "source": [
    "The Bahdanau Attention inspired the self-attention mechanism proposed in the transformer architecture.\n",
    "\n",
    "Self-attention gives the model the ability to compute attention weights that relate different positions within the same input sequence. In traditional attentions mechanisms, the relationships focused on elements of two different sequences, where the attention could be between an input sequence and an output sequence, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa934ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" style=\"max-width: 802.5px;\" viewBox=\"-5 -166 802.5 332\" role=\"graphics-document document\" aria-roledescription=\"block\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css\");</style><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-svg .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-svg .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:1px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg p{margin:0;}#mermaid-svg .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#mermaid-svg .cluster-label text{fill:#333;}#mermaid-svg .cluster-label span,#mermaid-svg p{color:#333;}#mermaid-svg .label text,#mermaid-svg span,#mermaid-svg p{fill:#333;color:#333;}#mermaid-svg .node rect,#mermaid-svg .node circle,#mermaid-svg .node ellipse,#mermaid-svg .node polygon,#mermaid-svg .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg .flowchart-label text{text-anchor:middle;}#mermaid-svg .node .label{text-align:center;}#mermaid-svg .node.clickable{cursor:pointer;}#mermaid-svg .arrowheadPath{fill:#333333;}#mermaid-svg .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#mermaid-svg .node .cluster{fill:rgba(255, 255, 222, 0.5);stroke:rgba(170, 170, 51, 0.2);box-shadow:rgba(50, 50, 93, 0.25) 0px 13px 27px -5px,rgba(0, 0, 0, 0.3) 0px 8px 16px -8px;stroke-width:1px;}#mermaid-svg .cluster text{fill:#333;}#mermaid-svg .cluster span,#mermaid-svg p{color:#333;}#mermaid-svg div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-svg .label-icon{display:inline-block;height:1em;overflow:visible;vertical-align:-0.125em;}#mermaid-svg .node .label-icon path{fill:currentColor;stroke:revert;stroke-width:revert;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g/><marker id=\"mermaid-svg_block-pointEnd\" class=\"marker block\" viewBox=\"0 0 10 10\" refX=\"6\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_block-pointStart\" class=\"marker block\" viewBox=\"0 0 10 10\" refX=\"4.5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 5 L 10 10 L 10 0 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_block-circleEnd\" class=\"marker block\" viewBox=\"0 0 10 10\" refX=\"11\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_block-circleStart\" class=\"marker block\" viewBox=\"0 0 10 10\" refX=\"-1\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_block-crossEnd\" class=\"marker cross block\" viewBox=\"0 0 11 11\" refX=\"12\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_block-crossStart\" class=\"marker cross block\" viewBox=\"0 0 11 11\" refX=\"-1\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><g class=\"block\"><g class=\"node default default flowchart-label\" id=\"input\" transform=\"translate(396.25, -132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-396.25\" y=\"-29\" width=\"792.5\" height=\"58\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x1\" transform=\"translate(69.375, -132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(-13.7890625, -9)\"><rect/><foreignObject width=\"27.578125\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">The</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x2\" transform=\"translate(200.125, -132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(-13.3515625, -9)\"><rect/><foreignObject width=\"26.703125\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">dog</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x3\" transform=\"translate(330.875, -132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(-25.34375, -9)\"><rect/><foreignObject width=\"50.6875\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">attacks</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x4\" transform=\"translate(461.625, -132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">the</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x5\" transform=\"translate(592.375, -132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(-13.78125, -9)\"><rect/><foreignObject width=\"27.5625\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">wild</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x6\" transform=\"translate(723.125, -132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(-10.671875, -9)\"><rect/><foreignObject width=\"21.34375\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">cat</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"embeddings\" transform=\"translate(396.25, 0)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-396.25\" y=\"-29\" width=\"792.5\" height=\"58\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"embedding1\" transform=\"translate(69.375, 0)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x1d1\" transform=\"translate(31.125, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x1d2\" transform=\"translate(69.375, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x1d3\" transform=\"translate(107.625, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.3</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"embedding2\" transform=\"translate(200.125, 0)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x2d1\" transform=\"translate(161.875, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x2d2\" transform=\"translate(200.125, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x2d3\" transform=\"translate(238.375, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"embedding3\" transform=\"translate(330.875, 0)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x3d1\" transform=\"translate(292.625, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.3</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x3d2\" transform=\"translate(330.875, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x3d3\" transform=\"translate(369.125, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"embedding4\" transform=\"translate(461.625, 0)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x4d1\" transform=\"translate(423.375, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x4d2\" transform=\"translate(461.625, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.3</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x4d3\" transform=\"translate(499.875, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"embedding5\" transform=\"translate(592.375, 0)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x5d1\" transform=\"translate(554.125, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x5d2\" transform=\"translate(592.375, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x5d3\" transform=\"translate(630.625, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"embedding6\" transform=\"translate(723.125, 0)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x6d1\" transform=\"translate(684.875, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.3</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x6d2\" transform=\"translate(723.125, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"x6d3\" transform=\"translate(761.375, 0)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"context_vectors\" transform=\"translate(396.25, 132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-396.25\" y=\"-29\" width=\"792.5\" height=\"58\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z1\" transform=\"translate(69.375, 132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z1d1\" transform=\"translate(31.125, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z1d2\" transform=\"translate(69.375, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.3</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z1d3\" transform=\"translate(107.625, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z2\" transform=\"translate(200.125, 132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z2d1\" transform=\"translate(161.875, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z2d2\" transform=\"translate(200.125, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z2d3\" transform=\"translate(238.375, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.3</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z3\" transform=\"translate(330.875, 132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z3d1\" transform=\"translate(292.625, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z3d2\" transform=\"translate(330.875, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z3d3\" transform=\"translate(369.125, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z4\" transform=\"translate(461.625, 132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z4d1\" transform=\"translate(423.375, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.3</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z4d2\" transform=\"translate(461.625, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z4d3\" transform=\"translate(499.875, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z5\" transform=\"translate(592.375, 132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z5d1\" transform=\"translate(554.125, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z5d2\" transform=\"translate(592.375, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z5d3\" transform=\"translate(630.625, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z6\" transform=\"translate(723.125, 132)\"><rect class=\"basic cluster composite label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-61.375\" y=\"-21\" width=\"122.75\" height=\"42\"/><g class=\"label\" style=\"\" transform=\"translate(0, 0)\"><rect/><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\"></span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z6d1\" transform=\"translate(684.875, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.1</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z6d2\" transform=\"translate(723.125, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.2</span></div></foreignObject></g></g><g class=\"node default default flowchart-label\" id=\"z6d3\" transform=\"translate(761.375, 132)\"><rect class=\"basic label-container\" style=\"\" rx=\"0\" ry=\"0\" x=\"-15.125\" y=\"-13\" width=\"30.25\" height=\"26\"/><g class=\"label\" style=\"\" transform=\"translate(-11.125, -9)\"><rect/><foreignObject width=\"22.25\" height=\"18\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: inline-block; white-space: nowrap;\"><span class=\"nodeLabel\">0.4</span></div></foreignObject></g></g><path d=\"M69.375,-111L69.375,-103.5C69.375,-96,69.375,-81,69.375,-66.667C69.375,-52.333,69.375,-38.667,69.375,-31.833L69.375,-25\" id=\"1-x1-embedding1\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M200.125,-111L200.125,-103.5C200.125,-96,200.125,-81,200.125,-66.667C200.125,-52.333,200.125,-38.667,200.125,-31.833L200.125,-25\" id=\"1-x2-embedding2\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M330.875,-111L330.875,-103.5C330.875,-96,330.875,-81,330.875,-66.667C330.875,-52.333,330.875,-38.667,330.875,-31.833L330.875,-25\" id=\"1-x3-embedding3\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M461.625,-111L461.625,-103.5C461.625,-96,461.625,-81,461.625,-66.667C461.625,-52.333,461.625,-38.667,461.625,-31.833L461.625,-25\" id=\"1-x4-embedding4\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M592.375,-111L592.375,-103.5C592.375,-96,592.375,-81,592.375,-66.667C592.375,-52.333,592.375,-38.667,592.375,-31.833L592.375,-25\" id=\"1-x5-embedding5\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M723.125,-111L723.125,-103.5C723.125,-96,723.125,-81,723.125,-66.667C723.125,-52.333,723.125,-38.667,723.125,-31.833L723.125,-25\" id=\"1-x6-embedding6\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M90.176,21L97.605,28.5C105.034,36,119.892,51,134.281,65.526C148.67,80.053,162.589,94.105,169.549,101.132L176.509,108.158\" id=\"1-embedding1-z2\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M200.125,21L200.125,28.5C200.125,36,200.125,51,200.125,65.333C200.125,79.667,200.125,93.333,200.125,100.167L200.125,107\" id=\"1-embedding2-z2\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M310.074,21L302.645,28.5C295.216,36,280.358,51,265.969,65.526C251.58,80.053,237.661,94.105,230.701,101.132L223.741,108.158\" id=\"1-embedding3-z2\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M420.023,21L405.165,28.5C390.307,36,360.591,51,331.47,65.7C302.349,80.399,273.824,94.798,259.561,101.998L245.298,109.198\" id=\"1-embedding4-z2\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M531,20.654L508.542,28.212C486.083,35.769,441.167,50.885,396.882,65.787C352.597,80.69,308.944,95.38,287.118,102.725L265.291,110.07\" id=\"1-embedding5-z2\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/><path d=\"M661.75,15.49L628.396,23.909C595.042,32.327,528.333,49.163,462.271,65.837C396.209,82.51,330.794,99.02,298.086,107.276L265.378,115.531\" id=\"1-embedding6-z2\" class=\"  edge-thickness-normal edge-pattern-solid flowchart-link LS-a1 LE-b1\" marker-end=\"url(#mermaid-svg_block-pointEnd)\"/></g></svg>"
      ],
      "text/plain": [
       "<mermaid.__main__.Mermaid at 0x1a2564da350>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = Graph(\n",
    "    \"Self-attention\",\n",
    "    \"\"\"\n",
    "block\n",
    "    columns 1\n",
    "                 \n",
    "    block:input:1\n",
    "        columns 6\n",
    "        x1[\"The\"] x2[\"dog\"] x3[\"attacks\"] x4[\"the\"] x5[\"wild\"] x6[\"cat\"]\n",
    "    end\n",
    "    space\n",
    "    block:embeddings:1\n",
    "        block:embedding1:1\n",
    "            columns 3\n",
    "            x1d1[\"0.1\"] x1d2[\"0.2\"] x1d3[\"0.3\"]\n",
    "        end\n",
    "        block:embedding2:1\n",
    "            columns 3\n",
    "            x2d1[\"0.4\"] x2d2[\"0.1\"] x2d3[\"0.2\"]\n",
    "        end\n",
    "        block:embedding3:1\n",
    "            columns 3\n",
    "            x3d1[\"0.3\"] x3d2[\"0.2\"] x3d3[\"0.1\"]\n",
    "        end\n",
    "        block:embedding4:1\n",
    "            columns 3\n",
    "            x4d1[\"0.2\"] x4d2[\"0.3\"] x4d3[\"0.1\"]\n",
    "        end\n",
    "        block:embedding5:1\n",
    "            columns 3\n",
    "            x5d1[\"0.1\"] x5d2[\"0.4\"] x5d3[\"0.2\"]\n",
    "        end\n",
    "        block:embedding6:1\n",
    "            columns 3\n",
    "            x6d1[\"0.3\"] x6d2[\"0.1\"] x6d3[\"0.4\"]\n",
    "        end\n",
    "    end\n",
    "    x1 --> embedding1\n",
    "    x2 --> embedding2\n",
    "    x3 --> embedding3\n",
    "    x4 --> embedding4\n",
    "    x5 --> embedding5\n",
    "    x6 --> embedding6\n",
    "    space\n",
    "    block:context_vectors:1\n",
    "        columns 6\n",
    "        block:z1:1\n",
    "            columns 3\n",
    "            z1d1[\"0.2\"] z1d2[\"0.3\"] z1d3[\"0.4\"]\n",
    "        end\n",
    "        block:z2:1\n",
    "            columns 3\n",
    "            z2d1[\"0.1\"] z2d2[\"0.4\"] z2d3[\"0.3\"]\n",
    "        end\n",
    "        block:z3:1\n",
    "            columns 3\n",
    "            z3d1[\"0.4\"] z3d2[\"0.2\"] z3d3[\"0.1\"]\n",
    "        end\n",
    "        block:z4:1\n",
    "            columns 3\n",
    "            z4d1[\"0.3\"] z4d2[\"0.1\"] z4d3[\"0.2\"]\n",
    "        end\n",
    "        block:z5:1\n",
    "            columns 3\n",
    "            z5d1[\"0.2\"] z5d2[\"0.4\"] z5d3[\"0.1\"]\n",
    "        end\n",
    "        block:z6:1\n",
    "            columns 3\n",
    "            z6d1[\"0.1\"] z6d2[\"0.2\"] z6d3[\"0.4\"]\n",
    "        end\n",
    "    end\n",
    "    embedding1 --> z2\n",
    "    embedding2 --> z2\n",
    "    embedding3 --> z2\n",
    "    embedding4 --> z2\n",
    "    embedding5 --> z2\n",
    "    embedding6 --> z2\n",
    "\n",
    "\"\"\",\n",
    "    config={\n",
    "        \"theme\": \"base\",\n",
    "        \"themeVariables\": {\n",
    "            \"primaryColor\": \"#350F0F\",\n",
    "            \"secondaryColor\": \"#e0e0e0\",\n",
    "            \"tertiaryColor\": \"#d0d0d0\",\n",
    "            \"lineColor\": \"#F8B229\",\n",
    "        },\n",
    "    },\n",
    ")\n",
    "render = md.Mermaid(sequence)\n",
    "render"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f954e",
   "metadata": {},
   "source": [
    "### 1.1. Simplified self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616c357",
   "metadata": {},
   "source": [
    "What self-attention does is transform each input embedding (a vector of N dimensions) into another vector called a context vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424493b",
   "metadata": {},
   "source": [
    "#### Context vectors\n",
    "\n",
    "Context vectors can be defined as \"enriched\" versions of the input token embeddings. Each context vector is a representation of one of the embeddings in the input sequence, but it contains information about all other tokens.\n",
    "\n",
    "#### Attention scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e7329",
   "metadata": {},
   "source": [
    "The first step to calculate the context vectors is to calculate intermediate values named attention scores. For each embedded token input, the attention scores is a vector with the dot products between its embeddings and the embeddings for each other token. The token for which the attention scores are being calculated is called the query token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ab949",
   "metadata": {},
   "source": [
    "Let's take this example, using the simple tokenizer and 3-dimensional embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe35d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:['The', ' ', 'dog', ' ', 'attacks', ' ', 'the', ' ', 'wild', ' ', 'cat']\n",
      "Token ids:tensor([1, 0, 4, 0, 2, 0, 5, 0, 6, 0, 3])\n",
      "Embeddings:\n",
      "tensor([[ 1.2221,  1.0395,  0.9608],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 0.6370,  1.3158, -0.4287],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 0.4214,  0.7452, -1.8389],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 1.9435, -0.8080, -0.8735],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 0.9367, -0.3077, -1.4196],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [-1.2497, -0.2485, -1.0530]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "input_sequence = \"The dog attacks the wild cat\"\n",
    "simple_tokenizer = SimpleTokenizer(input_sequence)\n",
    "print(f\"Tokens:{SimpleTokenizer.tokenize(input_sequence)}\")\n",
    "simple_token_ids = torch.tensor(simple_tokenizer.encode(input_sequence))\n",
    "embedding_layer = torch.nn.Embedding(simple_tokenizer.vocab_size, embedding_dim=3)\n",
    "\n",
    "embeddings = embedding_layer(simple_token_ids).detach() # detach() removes grad to reduce print clutter\n",
    "\n",
    "print(f\"Token ids:{simple_token_ids}\")\n",
    "print(f\"Embeddings:\\n{embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa4d069",
   "metadata": {},
   "source": [
    "The attention scores for the first token (embedding [ 1.2221,  1.0395,  0.9608]), can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887e5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.4975, -1.5764,  1.7344, -1.5764, -0.4773, -1.5764,  0.6959, -1.5764,\n",
      "        -0.5391, -1.5764, -2.7973])\n"
     ]
    }
   ],
   "source": [
    "e0 = embeddings[0] # using the first token (\"The\") as query\n",
    "attention_scores = torch.zeros(len(embeddings))\n",
    "for i, e in enumerate(embeddings):\n",
    "    for j, dim in enumerate(e): # dot product is the sum of the element-wise products\n",
    "        attention_scores[i] += e0[j] * e[j]\n",
    "    \n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d72c0",
   "metadata": {},
   "source": [
    "Pytorch has a dot product convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a234cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.4975, -1.5764,  1.7344, -1.5764, -0.4773, -1.5764,  0.6959, -1.5764,\n",
      "        -0.5391, -1.5764, -2.7973])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([torch.dot(e0, e) for e in embeddings]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1f6ea",
   "metadata": {},
   "source": [
    "Now let's get the attention scores for all the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e0296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.4975, -1.5764,  1.7344, -1.5764, -0.4773, -1.5764,  0.6959, -1.5764,\n",
      "         -0.5391, -1.5764, -2.7973],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [ 1.7344, -2.2430,  2.3208, -2.2430,  2.0373, -2.2430,  0.5492, -2.2430,\n",
      "          0.8003, -2.2430, -0.6715],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [-0.4773, -2.0108,  2.0373, -2.0108,  4.1144, -2.0108,  1.8230, -2.0108,\n",
      "          2.7759, -2.0108,  1.2246],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [ 0.6959, -0.3645,  0.5492, -0.3645,  1.8230, -0.3645,  5.1931, -0.3645,\n",
      "          3.3092, -0.3645, -1.3082],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [-0.5391, -0.7254,  0.8003, -0.7254,  2.7759, -0.7254,  3.3092, -0.7254,\n",
      "          2.9874, -0.7254,  0.4007],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [-2.7973,  0.5189, -0.6715,  0.5189,  1.2246,  0.5189, -1.3082,  0.5189,\n",
      "          0.4007,  0.5189,  2.7321]])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = torch.zeros(len(embeddings), len(embeddings))\n",
    "\n",
    "for i, ei in enumerate(embeddings):\n",
    "    attention_scores[i] = torch.tensor([torch.dot(ei, ej) for ej in embeddings])\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959e7f4",
   "metadata": {},
   "source": [
    "Or, more succintly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2acae302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.4975, -1.5764,  1.7344, -1.5764, -0.4773, -1.5764,  0.6959, -1.5764,\n",
      "         -0.5391, -1.5764, -2.7973],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [ 1.7344, -2.2430,  2.3208, -2.2430,  2.0373, -2.2430,  0.5492, -2.2430,\n",
      "          0.8003, -2.2430, -0.6715],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [-0.4773, -2.0108,  2.0373, -2.0108,  4.1144, -2.0108,  1.8230, -2.0108,\n",
      "          2.7759, -2.0108,  1.2246],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [ 0.6959, -0.3645,  0.5492, -0.3645,  1.8230, -0.3645,  5.1931, -0.3645,\n",
      "          3.3092, -0.3645, -1.3082],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [-0.5391, -0.7254,  0.8003, -0.7254,  2.7759, -0.7254,  3.3092, -0.7254,\n",
      "          2.9874, -0.7254,  0.4007],\n",
      "        [-1.5764,  2.1770, -2.2430,  2.1770, -2.0108,  2.1770, -0.3645,  2.1770,\n",
      "         -0.7254,  2.1770,  0.5189],\n",
      "        [-2.7973,  0.5189, -0.6715,  0.5189,  1.2246,  0.5189, -1.3082,  0.5189,\n",
      "          0.4007,  0.5189,  2.7321]])\n"
     ]
    }
   ],
   "source": [
    "attention_scores = embeddings @ embeddings.T\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb908972",
   "metadata": {},
   "source": [
    "#### Attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03331f8",
   "metadata": {},
   "source": [
    "The next step is to transform attention scores into attention **weights**. We can do this by normalizing each tensor so that they sum up to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d0e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: tensor([ 3.4975, -1.5764,  1.7344, -1.5764, -0.4773, -1.5764,  0.6959, -1.5764,\n",
      "        -0.5391, -1.5764, -2.7973])\n",
      "weights: tensor([-0.6064,  0.2733, -0.3007,  0.2733,  0.0828,  0.2733, -0.1207,  0.2733,\n",
      "         0.0935,  0.2733,  0.4850])\n",
      "sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "atscs0 = attention_scores[0]\n",
    "atwts0 = atscs0 / sum(atscs0)\n",
    "print(f\"scores: {atscs0}\", f\"weights: {atwts0}\", sep=\"\\n\")\n",
    "print(f\"sum: {atwts0.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c4fa9",
   "metadata": {},
   "source": [
    "However, it is more advisable to normalize by using the softmax function. This function is better for managing extreme values, and offers more favorable gradient properties. It also guarantees that all weights are positive, which makes outputs more interpretable as probabilities.\n",
    "\n",
    "$ \\omega(z)_i = \\frac{e^{z_i}}{\\sum^{K}_{j=1} e^{z_j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24a5389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights (softmax): tensor([0.7682, 0.0048, 0.1318, 0.0048, 0.0144, 0.0048, 0.0466, 0.0048, 0.0136,\n",
      "        0.0048, 0.0014])\n",
      "sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax(scores: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.exp(scores) / torch.exp(scores).sum(dim=0)\n",
    "\n",
    "atwts0_softmax = softmax(atscs0)\n",
    "print(f\"weights (softmax): {atwts0_softmax}\", f\"sum: {sum(atwts0_softmax)}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb1e0b",
   "metadata": {},
   "source": [
    "Of course, pytorch also has a built-in function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4334523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7682, 0.0048, 0.1318, 0.0048, 0.0144, 0.0048, 0.0466, 0.0048, 0.0136,\n",
       "        0.0048, 0.0014])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(atscs0, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1373d7",
   "metadata": {},
   "source": [
    "Let's get the attention weights for all the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca5336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights:\n",
      "tensor([[0.7682, 0.0048, 0.1318, 0.0048, 0.0144, 0.0048, 0.0466, 0.0048, 0.0136,\n",
      "         0.0048, 0.0014],\n",
      "        [0.0044, 0.1861, 0.0022, 0.1861, 0.0028, 0.1861, 0.0147, 0.1861, 0.0102,\n",
      "         0.1861, 0.0354],\n",
      "        [0.1987, 0.0037, 0.3571, 0.0037, 0.2689, 0.0037, 0.0607, 0.0037, 0.0781,\n",
      "         0.0037, 0.0179],\n",
      "        [0.0044, 0.1861, 0.0022, 0.1861, 0.0028, 0.1861, 0.0147, 0.1861, 0.0102,\n",
      "         0.1861, 0.0354],\n",
      "        [0.0065, 0.0014, 0.0800, 0.0014, 0.6389, 0.0014, 0.0646, 0.0014, 0.1675,\n",
      "         0.0014, 0.0355],\n",
      "        [0.0044, 0.1861, 0.0022, 0.1861, 0.0028, 0.1861, 0.0147, 0.1861, 0.0102,\n",
      "         0.1861, 0.0354],\n",
      "        [0.0091, 0.0031, 0.0078, 0.0031, 0.0280, 0.0031, 0.8144, 0.0031, 0.1238,\n",
      "         0.0031, 0.0012],\n",
      "        [0.0044, 0.1861, 0.0022, 0.1861, 0.0028, 0.1861, 0.0147, 0.1861, 0.0102,\n",
      "         0.1861, 0.0354],\n",
      "        [0.0083, 0.0069, 0.0318, 0.0069, 0.2294, 0.0069, 0.3910, 0.0069, 0.2835,\n",
      "         0.0069, 0.0213],\n",
      "        [0.0044, 0.1861, 0.0022, 0.1861, 0.0028, 0.1861, 0.0147, 0.1861, 0.0102,\n",
      "         0.1861, 0.0354],\n",
      "        [0.0021, 0.0569, 0.0173, 0.0569, 0.1153, 0.0569, 0.0092, 0.0569, 0.0506,\n",
      "         0.0569, 0.5208]])\n",
      "Sum sanity checks:\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "attention_weights = attention_scores.softmax(dim=1)\n",
    "print(f\"Attention weights:\\n{attention_weights}\")\n",
    "print(f\"Sum sanity checks:\\n{attention_weights.sum(dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c868b",
   "metadata": {},
   "source": [
    "#### Calculating context vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9252166",
   "metadata": {},
   "source": [
    "Finally, having the weights in hand, we calculate the context vectors by multiplying the embedded input tokens with the corresponding attention weights, then summing the resulting vectors.\n",
    "\n",
    "For example, using the first embedded token as query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd15ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings:\n",
      "tensor([[ 1.2221,  1.0395,  0.9608],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 0.6370,  1.3158, -0.4287],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 0.4214,  0.7452, -1.8389],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 1.9435, -0.8080, -0.8735],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [ 0.9367, -0.3077, -1.4196],\n",
      "        [-0.5300, -1.3035,  0.4438],\n",
      "        [-1.2497, -0.2485, -1.0530]])\n",
      "query: tensor([1.2221, 1.0395, 0.9608])\n",
      "weights(query): tensor([0.7682, 0.0048, 0.1318, 0.0048, 0.0144, 0.0048, 0.0466, 0.0048, 0.0136,\n",
      "        0.0048, 0.0014])\n"
     ]
    }
   ],
   "source": [
    "print(f\"embeddings:\\n{embeddings}\")\n",
    "print(f\"query: {e0}\")\n",
    "print(f\"weights(query): {atwts0_softmax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9653a",
   "metadata": {},
   "source": [
    "The embedding and its correspondent context vector will have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e084e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "ctxtv0 = torch.zeros(e0.shape)\n",
    "print(ctxtv0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7dee7a",
   "metadata": {},
   "source": [
    "For one query (which in in this case is the first embedding, e0), we loop through all the embeddings (including itself), multiplying each of them by the correspondent element in the query's attention weights vector. Then we sum the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe7e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.9388, 0.7985, 0.7381])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.13 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0839,  0.1734, -0.0565])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.01 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0061,  0.0108, -0.0265])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.05 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0906, -0.0377, -0.0407])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.01 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0127, -0.0042, -0.0193])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.00 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0018, -0.0004, -0.0015])\n",
      "context vector (query) = tensor([1.1176, 0.9091, 0.6043])\n"
     ]
    }
   ],
   "source": [
    "for i, ei in enumerate(embeddings):\n",
    "    weighted = atwts0_softmax[i] * ei\n",
    "    print(f\"{atwts0_softmax[i]:.2f} * {ei}  => {weighted}\",end=\"\\n\")\n",
    "    ctxtv0 += weighted\n",
    "print(f\"context vector (query) = {ctxtv0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd1a24",
   "metadata": {},
   "source": [
    "Generalizing for all the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec32d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 3])\n"
     ]
    }
   ],
   "source": [
    "context_vectors = torch.zeros(embeddings.shape)\n",
    "print(context_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e31d3b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.9388, 0.7985, 0.7381])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.13 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0839,  0.1734, -0.0565])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.01 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0061,  0.0108, -0.0265])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.05 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0906, -0.0377, -0.0407])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.01 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0127, -0.0042, -0.0193])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0025, -0.0063,  0.0021])\n",
      "0.00 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0018, -0.0004, -0.0015])\n",
      "-----done for query = embeddings[0]\n",
      "0.00 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0053, 0.0045, 0.0042])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0014,  0.0029, -0.0010])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0012,  0.0021, -0.0052])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0285, -0.0118, -0.0128])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0096, -0.0031, -0.0145])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.04 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0443, -0.0088, -0.0373])\n",
      "-----done for query = embeddings[1]\n",
      "0.20 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.2428, 0.2065, 0.1909])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0020, -0.0049,  0.0017])\n",
      "0.36 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.2275,  0.4699, -0.1531])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0020, -0.0049,  0.0017])\n",
      "0.27 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.1133,  0.2004, -0.4945])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0020, -0.0049,  0.0017])\n",
      "0.06 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.1180, -0.0491, -0.0530])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0020, -0.0049,  0.0017])\n",
      "0.08 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0731, -0.0240, -0.1108])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0020, -0.0049,  0.0017])\n",
      "0.02 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0224, -0.0045, -0.0189])\n",
      "-----done for query = embeddings[2]\n",
      "0.00 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0053, 0.0045, 0.0042])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0014,  0.0029, -0.0010])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0012,  0.0021, -0.0052])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0285, -0.0118, -0.0128])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0096, -0.0031, -0.0145])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.04 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0443, -0.0088, -0.0373])\n",
      "-----done for query = embeddings[3]\n",
      "0.01 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0079, 0.0067, 0.0062])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0007, -0.0018,  0.0006])\n",
      "0.08 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0510,  0.1053, -0.0343])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0007, -0.0018,  0.0006])\n",
      "0.64 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.2692,  0.4761, -1.1748])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0007, -0.0018,  0.0006])\n",
      "0.06 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.1256, -0.0522, -0.0564])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0007, -0.0018,  0.0006])\n",
      "0.17 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.1569, -0.0516, -0.2378])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0007, -0.0018,  0.0006])\n",
      "0.04 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0444, -0.0088, -0.0374])\n",
      "-----done for query = embeddings[4]\n",
      "0.00 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0053, 0.0045, 0.0042])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0014,  0.0029, -0.0010])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0012,  0.0021, -0.0052])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0285, -0.0118, -0.0128])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0096, -0.0031, -0.0145])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.04 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0443, -0.0088, -0.0373])\n",
      "-----done for query = embeddings[5]\n",
      "0.01 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0111, 0.0094, 0.0087])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0017, -0.0041,  0.0014])\n",
      "0.01 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0050,  0.0103, -0.0034])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0017, -0.0041,  0.0014])\n",
      "0.03 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0118,  0.0209, -0.0515])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0017, -0.0041,  0.0014])\n",
      "0.81 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 1.5827, -0.6580, -0.7114])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0017, -0.0041,  0.0014])\n",
      "0.12 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.1159, -0.0381, -0.1757])\n",
      "0.00 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0017, -0.0041,  0.0014])\n",
      "0.00 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0015, -0.0003, -0.0013])\n",
      "-----done for query = embeddings[6]\n",
      "0.00 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0053, 0.0045, 0.0042])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0014,  0.0029, -0.0010])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0012,  0.0021, -0.0052])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0285, -0.0118, -0.0128])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0096, -0.0031, -0.0145])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.04 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0443, -0.0088, -0.0373])\n",
      "-----done for query = embeddings[7]\n",
      "0.01 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0102, 0.0087, 0.0080])\n",
      "0.01 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0037, -0.0090,  0.0031])\n",
      "0.03 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0203,  0.0419, -0.0136])\n",
      "0.01 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0037, -0.0090,  0.0031])\n",
      "0.23 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0967,  0.1710, -0.4219])\n",
      "0.01 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0037, -0.0090,  0.0031])\n",
      "0.39 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.7600, -0.3160, -0.3416])\n",
      "0.01 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0037, -0.0090,  0.0031])\n",
      "0.28 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.2655, -0.0872, -0.4024])\n",
      "0.01 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0037, -0.0090,  0.0031])\n",
      "0.02 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0267, -0.0053, -0.0225])\n",
      "-----done for query = embeddings[8]\n",
      "0.00 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0053, 0.0045, 0.0042])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0014,  0.0029, -0.0010])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.00 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0012,  0.0021, -0.0052])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0285, -0.0118, -0.0128])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.01 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0096, -0.0031, -0.0145])\n",
      "0.19 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0986, -0.2425,  0.0826])\n",
      "0.04 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.0443, -0.0088, -0.0373])\n",
      "-----done for query = embeddings[9]\n",
      "0.00 * tensor([1.2221, 1.0395, 0.9608])  => tensor([0.0025, 0.0021, 0.0020])\n",
      "0.06 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0302, -0.0742,  0.0253])\n",
      "0.02 * tensor([ 0.6370,  1.3158, -0.4287])  => tensor([ 0.0110,  0.0228, -0.0074])\n",
      "0.06 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0302, -0.0742,  0.0253])\n",
      "0.12 * tensor([ 0.4214,  0.7452, -1.8389])  => tensor([ 0.0486,  0.0859, -0.2121])\n",
      "0.06 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0302, -0.0742,  0.0253])\n",
      "0.01 * tensor([ 1.9435, -0.8080, -0.8735])  => tensor([ 0.0178, -0.0074, -0.0080])\n",
      "0.06 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0302, -0.0742,  0.0253])\n",
      "0.05 * tensor([ 0.9367, -0.3077, -1.4196])  => tensor([ 0.0474, -0.0156, -0.0718])\n",
      "0.06 * tensor([-0.5300, -1.3035,  0.4438])  => tensor([-0.0302, -0.0742,  0.0253])\n",
      "0.52 * tensor([-1.2497, -0.2485, -1.0530])  => tensor([-0.6508, -0.1294, -0.5484])\n",
      "-----done for query = embeddings[10]\n"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(embeddings):\n",
    "    atwtsi = attention_weights[i]\n",
    "    # ctxtvi = torch.zeros(query.shape)\n",
    "    for j, ej in enumerate(embeddings):\n",
    "        weight = atwtsi[j]\n",
    "        weighted = weight * ej\n",
    "        print(f\"{weight:.2f} * {ej}  => {weighted}\",end=\"\\n\")\n",
    "        context_vectors[i] += weighted\n",
    "    print(f\"-----done for query = embeddings[{i}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd3d5f",
   "metadata": {},
   "source": [
    "Our final context vectors are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cace9237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all context vectors:\n",
      "tensor([[ 1.1176,  0.9091,  0.6043],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 0.7425,  0.7750, -0.6312],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 0.5625,  0.4664, -1.5314],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 1.7167, -0.6763, -0.9275],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 1.1076, -0.2321, -1.1786],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [-0.6744, -0.4126, -0.7193]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"all context vectors:\\n{context_vectors}\")\n",
    "# sanity check:\n",
    "(context_vectors[0] == ctxtv0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04400a",
   "metadata": {},
   "source": [
    "More concisely, we could have done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e79479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1176,  0.9091,  0.6043],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 0.7425,  0.7750, -0.6312],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 0.5625,  0.4664, -1.5314],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 1.7167, -0.6763, -0.9275],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [ 1.1076, -0.2321, -1.1786],\n",
      "        [-0.4914, -1.2268,  0.3463],\n",
      "        [-0.6744, -0.4126, -0.7193]])\n"
     ]
    }
   ],
   "source": [
    "context_vectors = attention_weights @ embeddings\n",
    "print(context_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041663f",
   "metadata": {},
   "source": [
    "### 1.2. Self-attention with trainable weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9792f",
   "metadata": {},
   "source": [
    "In order to add training to our self-attention mechanism, we must project the embbeded input tokens into three different vectors: a query vector (q), a key vector (k) and a value vector (v). Each of these vectors is an element of the weight matrices $W_q$, $W_k$, and $W_v$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8170de2",
   "metadata": {},
   "source": [
    "#### Context vector for a single token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc1976",
   "metadata": {},
   "source": [
    "We will start by computing the q, k and v vectors for a single embedded input token. Let's pick the second token this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ba594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = embeddings[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80462128",
   "metadata": {},
   "source": [
    "In GPT-like models, input and output dimensions are usually the same. But for better illustration, we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7628f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_in=3, d_out=2\n"
     ]
    }
   ],
   "source": [
    "d_in:int = e1.shape[0] # number of embedding dimensions\n",
    "d_out = 2\n",
    "print(f\"d_in={d_in}, d_out={d_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846eea9",
   "metadata": {},
   "source": [
    "Initializing $W_q$, $W_k$, and $W_v$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ad1ebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.8398, 0.8042],\n",
      "        [0.1213, 0.5309],\n",
      "        [0.6646, 0.4077]])\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.0888, 0.2429],\n",
      "        [0.7053, 0.6216],\n",
      "        [0.9188, 0.0185]])\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[0.8741, 0.0560],\n",
      "        [0.9659, 0.0073],\n",
      "        [0.3628, 0.4197]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False) # no grad to reduce output clutter\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "print(W_query,W_key,W_value, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5f178",
   "metadata": {},
   "source": [
    "Query, key and value vectors can be calculated by matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41ea46fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3083, -0.9373])\n",
      "tensor([-0.5587, -0.9308])\n",
      "tensor([-1.5614,  0.1471])\n"
     ]
    }
   ],
   "source": [
    "query_1:torch.Tensor = e1 @ W_query\n",
    "key_1:torch.Tensor = e1 @ W_key\n",
    "value_1:torch.Tensor = e1 @ W_value\n",
    "print(query_1, key_1, value_1, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd183b",
   "metadata": {},
   "source": [
    "Note that the output tensors have 2 columns as we specified in d_out.\n",
    "\n",
    "\n",
    "$M_{(i,j)} \\times M_{(j,k)} => M_{(i,k)}$\n",
    "\n",
    "Also note: **weight parameters** and **attention weights** are **not** the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd294e8",
   "metadata": {},
   "source": [
    "Even though we are computing the context vector for a single token, we still need they key and value vectors for all the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bd7b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key vectors (shape=torch.Size([11, 2])):\n",
      "tensor([[ 1.7245,  0.9609],\n",
      "        [-0.5587, -0.9308],\n",
      "        [ 0.5908,  0.9647],\n",
      "        [-0.5587, -0.9308],\n",
      "        [-1.1265,  0.5316],\n",
      "        [-0.5587, -0.9308],\n",
      "        [-1.2000, -0.0464],\n",
      "        [-0.5587, -0.9308],\n",
      "        [-1.4382,  0.0100],\n",
      "        [-0.5587, -0.9308],\n",
      "        [-1.2536, -0.4775]])\n",
      "\n",
      "value vectors (shape=torch.Size([11, 2])):\n",
      "tensor([[ 2.4211,  0.4793],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 1.6722, -0.1347],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 0.4209, -0.7427],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 0.6014, -0.2637],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 0.0065, -0.5456],\n",
      "        [-1.5614,  0.1471],\n",
      "        [-1.7144, -0.5137]])\n"
     ]
    }
   ],
   "source": [
    "key_vectors:torch.Tensor = embeddings @ W_key\n",
    "value_vectors:torch.Tensor = embeddings @ W_value\n",
    "print(f\"key vectors (shape={key_vectors.shape}):\\n{key_vectors}\", f\"value vectors (shape={value_vectors.shape}):\\n{value_vectors}\",sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc575a",
   "metadata": {},
   "source": [
    "##### Attention scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b11ef1f",
   "metadata": {},
   "source": [
    "The attention scores are once again calculated via dot product. But there's a difference:\n",
    "\n",
    "In the simplified case, the attention score was the dot product between two inputs. This time, the dot product is between the query and the transposed key vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f41cf",
   "metadata": {},
   "source": [
    "Calculating the attention score between the second embedding and itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0670bad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",=1.044725775718689\n"
     ]
    }
   ],
   "source": [
    "keys_1 = key_vectors[1]\n",
    "attn_score_1_1 = query_1.dot(keys_1)\n",
    "print(f\",={attn_score_1_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00598bab",
   "metadata": {},
   "source": [
    "All the attention scores in regards to the second embedding can be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08246f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4323,  1.0447, -1.0864,  1.0447, -0.1510,  1.0447,  0.4134,  1.0447,\n",
      "         0.4340,  1.0447,  0.8340])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_1_all = query_1 @ key_vectors.T\n",
    "print(attn_scores_1_all, attn_scores_1_all.shape, sep=\"\\n\")\n",
    "\n",
    "assert attn_score_1_1 == attn_scores_1_all[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6533ff",
   "metadata": {},
   "source": [
    "With the attention scores in hand, the next step would be to normalize them to get attention weights.\n",
    "\n",
    "However, in real-world models, with hundres or thousands of embedding dimensions, a common technique is commonly applied before normalization: **scaling down the attention weights by the square root of the embedding dimension of the keys.**\n",
    "\n",
    "Dot product grows together with the number of dimension, which can result in very small gradients during backpropagation since the softmax function ends up behaving almost like a step function - resulting in tiny gradients.\n",
    "\n",
    "This technique is the reason why this self-attention mechanism is also called *scaled-dot product attention*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f541177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention scores for embedding 1: tensor([-1.4323,  1.0447, -1.0864,  1.0447, -0.1510,  1.0447,  0.4134,  1.0447,\n",
      "         0.4340,  1.0447,  0.8340])\n",
      "scaled attention scores for embedding 1: tensor([-1.0128,  0.7387, -0.7682,  0.7387, -0.1067,  0.7387,  0.2923,  0.7387,\n",
      "         0.3069,  0.7387,  0.5897])\n"
     ]
    }
   ],
   "source": [
    "d_k = key_vectors.shape[-1] # this is the same as d_out\n",
    "scaled_attn_scores_1_all = attn_scores_1_all / (d_out ** 0.5)\n",
    "print(f\"attention scores for embedding 1: {attn_scores_1_all}\")\n",
    "print(f\"scaled attention scores for embedding 1: {scaled_attn_scores_1_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e306ba9",
   "metadata": {},
   "source": [
    "##### Attention weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2cab2",
   "metadata": {},
   "source": [
    "We now may apply the softmax function to the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02338b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention weights for embedding 1: tensor([0.0218, 0.1254, 0.0278, 0.1254, 0.0538, 0.1254, 0.0802, 0.1254, 0.0814,\n",
      "        0.1254, 0.1080])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_1_all = torch.softmax(scaled_attn_scores_1_all, dim=-1)\n",
    "print(f\"attention weights for embedding 1: {attn_weights_1_all}\", attn_weights_1_all.sum(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5e77d",
   "metadata": {},
   "source": [
    "##### Calculating the context vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9380a81",
   "metadata": {},
   "source": [
    "In the simplified case, the context vector for an input was calculated as the weighted sum **over the vector itself**.\n",
    "\n",
    "Now, the weighted sum performed **over the value vector** instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1dc19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0218, 0.1254, 0.0278, 0.1254, 0.0538, 0.1254, 0.0802, 0.1254, 0.0814,\n",
      "        0.1254, 0.1080])\n",
      "\n",
      "tensor([[ 2.4211,  0.4793],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 1.6722, -0.1347],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 0.4209, -0.7427],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 0.6014, -0.2637],\n",
      "        [-1.5614,  0.1471],\n",
      "        [ 0.0065, -0.5456],\n",
      "        [-1.5614,  0.1471],\n",
      "        [-1.7144, -0.5137]])\n"
     ]
    }
   ],
   "source": [
    "print(attn_weights_1_all, value_vectors, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78c16067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9935, -0.0622])\n",
      "tensor([-0.9935, -0.0622])\n"
     ]
    }
   ],
   "source": [
    "context_vector_1 = torch.zeros(d_out)\n",
    "for i, vvi in enumerate(value_vectors):\n",
    "    attn_weights_1_i = attn_weights_1_all[i]\n",
    "    context_vector_1 += attn_weights_1_i * vvi\n",
    "print(context_vector_1)\n",
    "\n",
    "# or\n",
    "\n",
    "context_vector_1 = attn_weights_1_all @ value_vectors\n",
    "print(context_vector_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95658a8f",
   "metadata": {},
   "source": [
    "#### Generalizing to all tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2821c57",
   "metadata": {},
   "source": [
    "We're gonna wrap all up by creating a module to perform the self-attention mechanism for the whole input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "317ecaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_P(torch.nn.Module): # _P for Parameter (as opposed to Linear which we'll see soon)\n",
    "    def __init__(self, d_in:int, d_out:int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W_query = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        key_vectors = x @ self.W_key\n",
    "        query_vectors = x @ self.W_query\n",
    "        value_vectors = x @ self.W_value\n",
    "\n",
    "        attn_scores = query_vectors @ key_vectors.T\n",
    "        scaled_attn_scores = attn_scores/(key_vectors.shape[-1] ** 0.5)\n",
    "        attn_weights = torch.softmax(scaled_attn_scores, dim=-1)\n",
    "        context_vectors = attn_weights @ value_vectors\n",
    "        \n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b8bed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1652e+00,  3.3566e-01],\n",
      "        [-9.9352e-01, -6.2155e-02],\n",
      "        [ 8.1129e-01,  3.4023e-04],\n",
      "        [-9.9352e-01, -6.2155e-02],\n",
      "        [-6.3151e-01, -1.8909e-01],\n",
      "        [-9.9352e-01, -6.2155e-02],\n",
      "        [ 1.1980e+00,  1.3611e-01],\n",
      "        [-9.9352e-01, -6.2155e-02],\n",
      "        [-4.8231e-01, -1.1911e-01],\n",
      "        [-9.9352e-01, -6.2155e-02],\n",
      "        [-1.0848e+00, -1.2670e-01]], grad_fn=<MmBackward0>)\n",
      "tensor([-0.9935, -0.0622], grad_fn=<SelectBackward0>) tensor([-0.9935, -0.0622])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "self_attention_P = SelfAttention_P(d_in=d_in, d_out=d_out)\n",
    "context_vectors_P = self_attention_P(embeddings)\n",
    "print(context_vectors_P)\n",
    "print (context_vectors_P[1],context_vector_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e0b94",
   "metadata": {},
   "source": [
    "We can use Linear instead of Parameter, which has a more optimized weight initialization method:\n",
    "\n",
    "\n",
    "(code moved to a module so it can be reused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eaca8f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class SelfAttention(torch.nn.Module):\n",
      "    def __init__(self, d_in:int, d_out:int, qkv_bias=False):\n",
      "        super().__init__()\n",
      "\n",
      "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
      "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
      "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
      "\n",
      "    def forward(self, x):\n",
      "        key_vectors = self.W_key(x)\n",
      "        query_vectors = self.W_query(x)\n",
      "        value_vectors = self.W_value(x)\n",
      "\n",
      "        attn_scores = query_vectors @ key_vectors.T\n",
      "        scaled_attn_scores = attn_scores/(key_vectors.shape[-1] ** 0.5)\n",
      "        attn_weights = torch.softmax(scaled_attn_scores, dim=-1)\n",
      "        context_vectors = attn_weights @ value_vectors\n",
      "        \n",
      "        return context_vectors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(SelfAttention))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78f4f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1785,  0.1088],\n",
      "        [ 0.1216, -0.1495],\n",
      "        [ 0.1985,  0.1906],\n",
      "        [ 0.1216, -0.1495],\n",
      "        [ 0.2426,  0.2571],\n",
      "        [ 0.1216, -0.1495],\n",
      "        [ 0.2941,  0.2379],\n",
      "        [ 0.1216, -0.1495],\n",
      "        [ 0.2602,  0.2216],\n",
      "        [ 0.1216, -0.1495],\n",
      "        [ 0.1258, -0.0132]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(69)\n",
    "self_attention_L = SelfAttention(d_in=d_in, d_out=d_out)\n",
    "print(self_attention_L(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5e9c2",
   "metadata": {},
   "source": [
    "Since the weight initialization is different, naturally the results are different. But we can assign the weights from Linear version to Parameter version to check if the results are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "983bad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0888, 0.2429],\n",
      "        [0.7053, 0.6216],\n",
      "        [0.9188, 0.0185]], requires_grad=True)\n",
      "Linear(in_features=3, out_features=2, bias=False)\n"
     ]
    }
   ],
   "source": [
    "print(self_attention_P.W_key, self_attention_L.W_key,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680b96c",
   "metadata": {},
   "source": [
    "The two classes have different data types for the weight matrices.\n",
    "We must compatibilize these. We will try to create Parameters objects from the Linear objects we have at the second class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b5c2e7",
   "metadata": {},
   "source": [
    "Accessing the weights of the linear self-attention object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06c70a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4748, -0.2969,  0.2371],\n",
       "        [ 0.1405,  0.4836, -0.5560]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention_L.W_key.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06133d7",
   "metadata": {},
   "source": [
    "The weights are of Parameter type, but seem to be transposed, so we must create Parameter objects from the transposed weight matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efbe9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention_P.W_key = torch.nn.Parameter(self_attention_L.W_key.weight.T)\n",
    "self_attention_P.W_value = torch.nn.Parameter(self_attention_L.W_value.weight.T)\n",
    "self_attention_P.W_query = torch.nn.Parameter(self_attention_L.W_query.weight.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438af593",
   "metadata": {},
   "source": [
    "Testing to see if we get the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05dedb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention_L(embeddings)==self_attention_P(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f2e49",
   "metadata": {},
   "source": [
    "## 2. Causal attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1bd4bd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
